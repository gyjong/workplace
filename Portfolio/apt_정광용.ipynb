{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e414302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import koreanize_matplotlib\n",
    "\n",
    "# 그래프에 retina display 적용\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# plt.rcParams['font.family'] = 'NanumGothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글폰트 확인\n",
    "pd.Series([1, 3, -5, 7]).plot(title=\"한글\", figsize=(5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "\n",
    "train_df = pd.read_csv('/Users/kenny_jung/aiffel/data/apt/train_30.csv')\n",
    "test_df = pd.read_csv('/Users/kenny_jung/aiffel/data/apt/test.csv')\n",
    "park = pd.read_csv('/Users/kenny_jung/aiffel/data/apt/park.csv')\n",
    "daycare = pd.read_csv('/Users/kenny_jung/aiffel/data/apt/day_care_center.csv')\n",
    "hospital = pd.read_csv('/Users/kenny_jung/aiffel/data/apt/hospital.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69bc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 시각화\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(train_df.isnull(), cmap='Blues')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3902cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "park.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4a7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "park.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 시각화\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(park.isnull(), cbar=False, cmap='Blues')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895eebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "daycare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "daycare.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "daycare['baby_teacher'] = daycare['day_care_baby_num'] / daycare['teacher_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a746bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "daycare['commuting_vehicle'] = daycare['is_commuting_vehicle'].map({'Y': 1, 'N': 0, '': 0, 'y': 1, 'n': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4007c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 시각화\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(daycare.isnull(), cbar=False, cmap='Blues')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ad8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'city', 'gu', 'day_care_type' 별로 그룹화하고 각 그룹의 레코드 수를 계산\n",
    "group = daycare.groupby(['city', 'gu', 'day_care_type']).size().reset_index(name='counts')\n",
    "\n",
    "# 'day_care_type' 별로 컬럼을 만들고, NaN 값을 0으로 채우기\n",
    "daycare_group = group.pivot_table(index=['city', 'gu'], columns='day_care_type', values='counts', fill_value=0).reset_index()\n",
    "\n",
    "# 'day_care' total 컬럼 추가\n",
    "daycare_group['total'] = daycare_group['가정'] + daycare_group['국공립'] + daycare_group['민간'] + daycare_group['법인·단체'] + daycare_group['사회복지법인'] + daycare_group['직장'] + daycare_group['협동'] \n",
    "\n",
    "# 컬럼 이름에 'daycare_' 추가\n",
    "daycare_group.columns = ['daycare_' + col if col not in ['city', 'gu'] else col for col in daycare_group.columns]\n",
    "\n",
    "# 컬럼 이름을 간결하게 만들기\n",
    "daycare_group.columns.name = None\n",
    "daycare_group = daycare_group.reset_index(drop=True)\n",
    "daycare_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'city'와 'gu' 기준으로 'baby_teacher'의 평균과 'commuting_vehicle'의 합을 계산합니다.\n",
    "grouped = daycare.groupby(['city', 'gu']).agg({'baby_teacher': 'mean', 'commuting_vehicle': 'sum'}).reset_index()\n",
    "\n",
    "# 계산된 결과를 'daycare_group'에 병합합니다.\n",
    "daycare_group = pd.merge(daycare_group, grouped, on=['city', 'gu'], how='left')\n",
    "\n",
    "# 열 이름을 변경합니다.\n",
    "daycare_group.rename(columns={'baby_teacher': 'avg_baby_teacher', 'commuting_vehicle': 'sum_commuting_vehicle'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "daycare_group.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04416ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "daycare_group.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82362110",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=daycare, x='city', hue='day_care_type', palette='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e056114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'city', 'gu', 'dong', 'park_type' 별로 그룹화하고 각 그룹의 레코드 수를 계산\n",
    "group = park.groupby(['city', 'gu', 'dong', 'park_type']).size().reset_index(name='counts')\n",
    "\n",
    "# 'park_type' 별로 컬럼을 만들고, NaN 값을 0으로 채우기\n",
    "park_group = group.pivot_table(index=['city', 'gu', 'dong'], columns='park_type', values='counts', fill_value=0).reset_index()\n",
    "\n",
    "# 'park' total 컬럼 추가\n",
    "park_group['total'] = park_group['근린공원'] + park_group['기타'] + park_group['도시농업공원'] + park_group['묘지공원'] + park_group['문화공원'] + park_group['소공원'] + park_group['수변공원'] + park_group['어린이공원'] + park_group['역사공원'] + park_group['체육공원']\n",
    "\n",
    "# 컬럼 이름에 'park_' 추가\n",
    "park_group.columns = ['park_' + col if col not in ['city', 'gu', 'dong'] else col for col in park_group.columns]\n",
    "\n",
    "# 컬럼 이름을 간결하게 만들기\n",
    "park_group.columns.name = None\n",
    "park_group = park_group.reset_index(drop=True)\n",
    "park_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'city', 'gu'와 'dong' 기준으로 'part_area'의 합을 계산합니다.\n",
    "grouped = park.groupby(['city', 'gu', 'dong']).agg({'park_area': 'sum'}).reset_index()\n",
    "\n",
    "# 계산된 결과를 'park_group'에 병합합니다.\n",
    "park_group = pd.merge(park_group, grouped, on=['city', 'gu', 'dong'], how='left')\n",
    "\n",
    "# 열 이름을 변경합니다.\n",
    "# park_group.rename(columns={'park_area': 'sum_part_area'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "park_group.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286153bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=park, x='city', hue='park_type', palette='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a6689",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_gu_dong = pd.read_csv('/Users/kenny_jung/aiffel/datathon/aiffel_datathon/data/city_gu_dong.csv')\n",
    "city_gu_dong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df에 'city', 'dong'을 기준으로 'gu' 추가\n",
    "train_df = pd.merge(train_df, city_gu_dong[['city', 'dong', 'gu']], on=['city', 'dong'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed45473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'city'와 'gu'를 기준으로 'train_df'와 'daycare_group'를 병합합니다.\n",
    "# 'left' 방식을 사용하여 'train_df'의 모든 행을 유지하고, 'daycare_group'에서 일치하는 행을 병합합니다.\n",
    "train_df = pd.merge(train_df, daycare_group, on=['city', 'gu'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf47c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'city', 'gu', 'dong' 을 기준으로 'train_df'와 'park_group'를 병합합니다.\n",
    "# 'left' 방식을 사용하여 'train_df'의 모든 행을 유지하고, 'park_group'에서 일치하는 행을 병합합니다.\n",
    "train_df = pd.merge(train_df, park_group, on=['city', 'gu', 'dong'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eaa57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'city', 'dong' 을 기준으로 'train_df'와 'hospital'를 병합합니다.\n",
    "# 'left' 방식을 사용하여 'train_df'의 모든 행을 유지하고, 'hospital'에서 일치하는 행을 병합합니다.\n",
    "train_df = pd.merge(train_df, hospital, on=['city', 'dong'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 열 이름을 가져옵니다.\n",
    "cols = list(train_df.columns)\n",
    "\n",
    "# 'transaction_real_price'를 제거합니다.\n",
    "cols.remove('transaction_real_price')\n",
    "\n",
    "# 'transaction_real_price'를 마지막에 추가합니다.\n",
    "cols.append('transaction_real_price')\n",
    "\n",
    "# 새로운 열 순서를 DataFrame에 적용합니다.\n",
    "train_df = train_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce65cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3287fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1492861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 시각화\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(train_df.isnull(), cbar=False, cmap='Blues')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a08a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_df.corr(numeric_only=True)\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "fig = plt.figure(figsize=(15, 13))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.2, vmin = -1, vmax = 1, mask = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae813499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numeric columns\n",
    "numeric_train_df = train_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate correlation\n",
    "corr = numeric_train_df.corr()['transaction_real_price'].sort_values(ascending=False)\n",
    "\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d590e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "sns.barplot(x=corr.values, y=corr.index, hue=corr.index, dodge=False, palette='coolwarm_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54acdcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'dong' 별로 'transaction_real_price'의 평균을 계산합니다.\n",
    "avg_price_by_dong = train_df.groupby('dong')['transaction_real_price'].mean().reset_index()\n",
    "\n",
    "# 결과를 시각화합니다.\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=avg_price_by_dong, x='dong', y='transaction_real_price')\n",
    "plt.xticks(rotation=90)  # x축 레이블이 겹치지 않도록 회전시킵니다.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac833fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_price_by_dong.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fe22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['transaction_real_price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7163c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data = avg_price_by_dong, x='transaction_real_price', color='skyblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df70486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a7d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fb996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# from geopy.geocoders import Nominatim\n",
    "\n",
    "# train_df = pd.read_csv('/Users/kenny_jung/aiffel/data/apt/train.csv')\n",
    "\n",
    "\n",
    "# # Geopy를 사용하여 위도와 경도를 조회하는 함수\n",
    "# def get_lat_lon(address):\n",
    "#     geolocator = Nominatim(user_agent=\"kenny\")\n",
    "#     location = geolocator.geocode(address)\n",
    "#     if location:\n",
    "#         return location.latitude, location.longitude\n",
    "#     else:\n",
    "#         return None, None\n",
    "\n",
    "# # 'addr_kr' 열의 각 주소에 대해 위도와 경도 조회\n",
    "# # tqdm을 사용하여 진행 상황을 표시\n",
    "# tqdm.pandas()\n",
    "# train_df[['latitude', 'longitude']] = train_df['addr_kr'][5001:10000].progress_apply(get_lat_lon).apply(pd.Series)\n",
    "\n",
    "# print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0bb963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv('/Users/kenny_jung/aiffel/data/apt/train_merged.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['city', 'dong', 'apt', 'gu', ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24522c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무한대 값을 NaN으로 대체합니다.\n",
    "train_df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c1e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 열의 결측치를 해당 열의 중앙값으로 채웁니다.\n",
    "train_df.fillna(train_df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe68a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv('/Users/kenny_jung/aiffel/data/apt/train_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35fa4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error, mean_absolute_percentage_error\n",
    "\n",
    "X = train_df.drop('transaction_real_price', axis=1)\n",
    "y = train_df['transaction_real_price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)\n",
    "model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('R2 score:', r2_score(y_test, y_pred))\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bdeeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8501803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'transaction_real_price' 열에 대해 IQR을 계산합니다.\n",
    "Q1 = train_df['transaction_real_price'].quantile(0.25)\n",
    "Q3 = train_df['transaction_real_price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 1.5 x IQR 규칙에 따라 이상치를 제거합니다.\n",
    "train_df = train_df[~((train_df['transaction_real_price'] < (Q1 - 1.5 * IQR)) | (train_df['transaction_real_price'] > (Q3 + 1.5 * IQR)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e085d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b33c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error, mean_absolute_percentage_error\n",
    "\n",
    "X = train_df.drop('transaction_real_price', axis=1)\n",
    "y = train_df['transaction_real_price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)\n",
    "model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('R2 score:', r2_score(y_test, y_pred))\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bb95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression     # 선형 회귀\n",
    "from sklearn.linear_model import SGDRegressor         # 확률적 경사하강법\n",
    "from sklearn.tree import DecisionTreeRegressor        # 의사결정나무\n",
    "from sklearn.ensemble import RandomForestRegressor    # 앙상블 모델 - 랜덤포레스트\n",
    "from sklearn.svm import SVR                           # 서포트 벡터 머신\n",
    "from xgboost import XGBRegressor                      # XGBoost\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error, mean_absolute_percentage_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['font.family'] = 'Avenir'\n",
    "\n",
    "X = train_df.drop('transaction_real_price', axis=1)\n",
    "y = train_df['transaction_real_price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)\n",
    "\n",
    "MAE = [] # mean_absolute_error(true, preds)\n",
    "MSE = [] # mean_squared_error(true, preds)\n",
    "RMSE = [] # np.sqrt(mean_squared_error(true, preds))\n",
    "MLSE = [] # mean_squared_log_error(true, preds)\n",
    "RMSLE = [] # np.sqrt(mean_squared_log_error(true, preds))\n",
    "R2 = [] # r2_score(true, preds)\n",
    "\n",
    "for model in [DecisionTreeRegressor(), \n",
    "              RandomForestRegressor(n_jobs=-1), \n",
    "              # SVR(kernel='linear'), \n",
    "              # SGDRegressor(), \n",
    "              LinearRegression(n_jobs=-1),\n",
    "              XGBRegressor(n_jobs=-1)\n",
    "              ]:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(model.__class__.__name__, r2_score(y_test, y_pred))\n",
    "    MAE.append(mean_absolute_error(y_test, y_pred))\n",
    "    MSE.append(mean_squared_error(y_test, y_pred))\n",
    "    RMSE.append(np.sqrt(mean_squared_error(y_test, y_pred,)))\n",
    "    # MLSE.append(mean_squared_log_error(y_test, y_pred))\n",
    "    # RMSLE.append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    R2.append(r2_score(y_test, y_pred))\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "sns.barplot(y=R2, x=['DecisionTree', 'RandomForest', 'Linear', 'XGB'], hue = R2, palette='crest', ax=ax[0]) \n",
    "for i, R2 in enumerate(R2):\n",
    "    ax[0].text(i, R2, round(R2, 4), ha='center', va='bottom')\n",
    "ax[0].legend().remove()\n",
    "ax[0].set_ylim([0.6, 1])\n",
    "ax[0].set_title('R2 of each model')\n",
    "\n",
    "sns.lineplot(x=['DecisionTree', 'RandomForest', 'Linear', 'XGB'], y=MAE, label='MAE', ax=ax[1], marker='o')\n",
    "sns.lineplot(x=['DecisionTree', 'RandomForest', 'Linear', 'XGB'], y=RMSE, label='RMSE', ax=ax[1], marker='^', markersize=10)\n",
    "# sns.lineplot(x=['DecisionTree', 'RandomForest', 'SGD', 'Linear', 'XGB'], y=RMSLE, label='RMSLE', ax=ax[1], marker='s')\n",
    "ax[1].set_title('MAE/RMSE of each model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error, mean_absolute_percentage_error\n",
    "\n",
    "X = train_df.drop('transaction_real_price', axis=1)\n",
    "y = train_df['transaction_real_price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)\n",
    "model = RandomForestRegressor(n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('R2 score:', r2_score(y_test, y_pred))\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78536944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 하이퍼파라미터를 가져옵니다.\n",
    "parameters = model.get_params()\n",
    "\n",
    "# 하이퍼파라미터를 출력합니다.\n",
    "for param, value in parameters.items():\n",
    "    print(f'{param}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1474ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# params={    \n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     # 랜덤 포레스트에서 생성할 트리의 개수를 지정합니다. 이 값이 클수록 모델은 복잡해지고, 오버피팅의 위험이 있습니다.\n",
    "#     # 높은 값이 더 좋은 성능을 보장하지는 않습니다.\n",
    "#     'max_depth': [None, 5, 10, 20],\n",
    "#     # 각 트리의 최대 깊이를 지정합니다. 이 값이 클수록 모델은 복잡해지고, 오버피팅의 위험이 있습니다. None으로 설정하면, 노드가 모든 리프가 순수해질 때까지 확장됩니다. \n",
    "#     'min_samples_split': [0.01, 0.1, 1, 2, 5],\n",
    "#     # 노드를 분할하기 위한 최소한의 샘플 데이터 수입니다. 이 값보다 적게 샘플이 있다면, 노드는 분할되지 않습니다.\n",
    "#     # 높은 값은 모델을 안정적으로 만들지만, 과소적합의 위험이 있습니다.\n",
    "#     'min_samples_leaf': [1, 2, 5],\n",
    "#     # 리프 노드가 되기 위한 최소한의 샘플 데이터 수입니다. 이 값보다 적게 샘플이 있다면, 리프 노드는 생성되지 않습니다.\n",
    "#     # 높은 값은 모델을 안정적으로 만들지만, 과소적합의 위험이 있습니다.\n",
    "#     'max_features': [1, 2, 5, 10, 'auto', 'sqrt']\n",
    "#     # 각 노드에서 분할에 사용할 특성의 최대 개수입니다.\n",
    "#     # 'auto'로 설정하면, max_features = n_features입니다.\n",
    "#     # 'sqrt'로 설정하면, max_features = sqrt(n_features)입니다.\n",
    "# }\n",
    "\n",
    "# # grid = GridSearchCV(model, param_grid=params, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid = RandomizedSearchCV(model, param_distributions=params, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "# grid.fit(X_train, y_train)\n",
    "# best_parameters_rf = grid.best_params_  \n",
    "# best_score_rf = grid.best_score_ \n",
    "# print(best_parameters_rf)\n",
    "# print(best_score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b6daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn.metrics import make_scorer\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import numpy as np\n",
    "\n",
    "# # 하이퍼파라미터 그리드를 정의합니다.\n",
    "# param_distributions = {\n",
    "#     'n_estimators': [50, 100, 200, 300],\n",
    "#     'max_features': [1.0, 0.3, 0.1],\n",
    "#     'max_depth': [None, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# # RMSE 스코어 함수를 정의합니다.\n",
    "# rmse = make_scorer(lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred)), greater_is_better=False)\n",
    "\n",
    "# # RandomizedSearchCV를 사용하여 하이퍼파라미터 튜닝을 수행합니다.\n",
    "# # random_search = RandomizedSearchCV(estimator=model, param_distributions=param_distributions, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1, scoring=rmse)\n",
    "# random_search = GridSearchCV(estimator=model, param_grid=param_distributions, cv=3, verbose=2, n_jobs=-1, scoring=rmse)\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# # 최적의 하이퍼파라미터를 출력합니다.\n",
    "# print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5687466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error, mean_absolute_percentage_error\n",
    "\n",
    "# X = train_df.drop('transaction_real_price', axis=1)\n",
    "# y = train_df['transaction_real_price']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)\n",
    "# model = RandomForestRegressor(\n",
    "#                 bootstrap = True,\n",
    "#                 ccp_alpha = 0.0,\n",
    "#                 criterion = 'squared_error',\n",
    "#                 max_depth = None,\n",
    "#                 max_features = 1.0, \n",
    "#                 max_leaf_nodes = None,\n",
    "#                 max_samples = None,\n",
    "#                 min_impurity_decrease = 0.0,\n",
    "#                 min_samples_leaf = 1,\n",
    "#                 min_samples_split = 5,\n",
    "#                 min_weight_fraction_leaf = 0.0,\n",
    "#                 n_estimators = 100,\n",
    "#                 n_jobs = -1,\n",
    "#                 oob_score = False,\n",
    "#                 random_state = None,\n",
    "#                 verbose = 0,\n",
    "#                 warm_start = False\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "# print('R2 score:', r2_score(y_test, y_pred))\n",
    "# print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "# print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "# print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d74e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data = train_df, x='transaction_real_price', color='skyblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_df.corr(numeric_only=True)\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "fig = plt.figure(figsize=(15, 13))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.2, vmin = -1, vmax = 1, mask = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d6365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numeric columns\n",
    "numeric_train_df = train_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate correlation\n",
    "corr = numeric_train_df.corr()['transaction_real_price'].sort_values(ascending=False)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "sns.barplot(x=corr.values.flatten(), y=corr.index, hue=corr.index, dodge=False, palette='coolwarm_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ba505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shap values\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute Mean SHAP values\n",
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a860c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm plot\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layered violine plot\n",
    "shap.plots.violin(shap_values, plot_type = 'layered_violin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4904cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
